[
  {
    "path": "posts/2021-05-27-introduction-to-purrr/",
    "title": "1. Introduction to {purrr}",
    "description": "A basic introductory tutorial of the `purrr::map()` family",
    "author": [
      {
        "name": "Shijing Zhou",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [],
    "contents": "\nWhat is {purrr}?\n{purrr} is a handy package that provides a number of helpful functions often used for iteration with functions and vectors. In this tutorial, different uses of purrr::map() and its variants are demonstrated.\nWhat can you do with purrr::map()?\npurrr::map() and its variants are functionals, meaning they are functions that take another function as input, apply that function to the specified data, and return the resulting vector as output. purrr::map() and its “family” of functions allow you to transform their input by applying a function to each element of a list or atomic vector, and it will return an object of the same length as the input. The difference between purrr::map() and its variants is that purrr::map() always returns a list, but other variants return an atomic vector of the indicated type.\nSome commonly used variants include:\npurrr::map_lgl(): returns a logical type vector\npurrr::map_int(): returns a integer type vector\npurrr::map_dbl(): returns a double type vector\npurrr::map_char(): returns a character type vector\npurrr::map_df(): returns a data frame, often used for batch load data\nThe map() family’s arguments are relatively simple, but it can take a while to get used to them. Its basic anatomy is as follows:\n\n\nmap(your_data, some_function_or_formula_or_vector, any_necessary_arguments_for_function)\n\n\n\nFor example,\n\n\nmap_dbl(data, mean, na.rm = TRUE)\n\n\n\nwould return a vector containing the mean (removing NAs) of each column of data.\nInstead of supplying a function as input, you can also write equivalent code supplying a formula instead.\n\n\nmap_dbl(data, ~mean(.x, na.rm = TRUE))\n\n\n\nYou can also input “anonymous” functions\n\n\nmap_dbl(data, function(x) x + 2)\n\n\n\nand vectors for indexing.\n\n\nmap(your_complex_list, c(1, 4))\n\n\n\nLet’s demontrate purrr::map() with a few examples from real data\nLoad package and data\nFor this tutorial, we will be utilizing an open dataset that contains N=2495 individuals’ responses to a conspiracist ideation measure called the Generic Conspiracist Beliefs Scale (GCBS; Brotherton et al., 2013), a personality measure called the Ten Item Personality Inventory (TIPI; Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr., 2003), and various demographic and validity check items. For more information about the data, see our second post.\n\n\nlibrary(tidyverse) # note: {purrr} is a {tidyverse} package\nconspiracy <- rio::import(here::here(\"content\", \"dataCT.csv\"))\n\n\n\nLet’s take a look at those variables in the dataset.\n\n\nstr(conspiracy)\n\n\n'data.frame':   2495 obs. of  72 variables:\n $ Q1          : int  5 5 2 5 5 1 4 5 1 1 ...\n $ Q2          : int  5 5 4 4 4 1 3 4 1 2 ...\n $ Q3          : int  3 5 1 1 1 1 3 3 1 1 ...\n $ Q4          : int  5 5 2 2 4 1 3 3 1 1 ...\n $ Q5          : int  5 5 2 4 4 1 4 4 1 1 ...\n $ Q6          : int  5 3 2 5 5 1 3 5 1 5 ...\n $ Q7          : int  5 5 4 4 4 1 3 5 1 1 ...\n $ Q8          : int  3 5 2 1 3 1 4 5 1 1 ...\n $ Q9          : int  4 1 2 4 1 1 2 5 1 1 ...\n $ Q10         : int  5 4 4 5 5 1 3 5 1 4 ...\n $ Q11         : int  5 4 2 5 5 1 3 5 1 1 ...\n $ Q12         : int  5 5 4 5 5 1 2 5 1 1 ...\n $ Q13         : int  3 4 0 1 3 1 2 3 1 1 ...\n $ Q14         : int  5 4 2 4 5 1 3 4 1 1 ...\n $ Q15         : int  5 5 4 5 5 1 4 5 1 5 ...\n $ E1          : int  7070 4086 27535 4561 8841 15267 7249 8024 4654 23787 ...\n $ E2          : int  7469 13107 7814 5589 7575 7112 4651 7343 6076 12375 ...\n $ E3          : int  7383 2807 7762 3506 3832 4798 5496 6808 3032 2006 ...\n $ E4          : int  6540 5030 10290 3784 7775 5214 3936 6794 3984 3650 ...\n $ E5          : int  9098 7405 8558 5093 4160 3683 7831 8743 4328 3188 ...\n $ E6          : int  4998 7864 10538 3555 5216 4130 6816 6196 4070 48851 ...\n $ E7          : int  6971 16234 4740 3158 7559 4487 6167 7762 4012 9013 ...\n $ E8          : int  4713 2603 4162 1887 5792 2376 2032 4797 2430 2128 ...\n $ E9          : int  6032 14174 6492 7678 10296 3273 4000 8015 4191 2898 ...\n $ E10         : int  5878 9423 11512 2304 5455 5501 3583 5764 8444 10420 ...\n $ E11         : int  4031 11683 6874 3604 3864 3790 4481 5717 4224 5820 ...\n $ E12         : int  4386 12718 11440 2724 11799 7777 5071 5352 4404 2049 ...\n $ E13         : int  9077 4816 0 2689 7872 4553 2368 6387 1065 9901 ...\n $ E14         : int  5113 6806 11418 2657 10543 5944 4408 9671 5533 3838 ...\n $ E15         : int  4204 4823 9872 3824 4224 4028 6103 5622 4964 7208 ...\n $ introelapse : int  11 6 7 5 4 35 12 27 2 26 ...\n $ testelapse  : int  95 125 141 58 105 87 75 104 67 148 ...\n $ surveyelapse: int  142 144 90 135 210 154 67 186 121 118 ...\n $ TIPI1       : int  5 6 6 6 1 4 2 4 4 1 ...\n $ TIPI2       : int  3 7 6 7 3 2 5 5 5 6 ...\n $ TIPI3       : int  6 6 6 7 7 6 4 6 6 3 ...\n $ TIPI4       : int  2 7 1 5 2 2 2 2 2 1 ...\n $ TIPI5       : int  6 6 7 7 6 6 5 7 4 5 ...\n $ TIPI6       : int  6 3 5 6 4 5 6 4 5 7 ...\n $ TIPI7       : int  7 7 6 5 5 6 2 5 6 6 ...\n $ TIPI8       : int  2 5 5 1 5 3 3 5 2 5 ...\n $ TIPI9       : int  7 1 7 5 5 6 5 3 7 7 ...\n $ TIPI10      : int  1 1 7 1 3 2 5 1 2 4 ...\n $ VCL1        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL2        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL3        : int  1 0 1 1 0 1 0 0 0 1 ...\n $ VCL4        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL5        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL6        : int  0 0 1 0 0 0 0 0 0 0 ...\n $ VCL7        : int  0 0 1 0 0 0 0 0 0 0 ...\n $ VCL8        : int  0 0 1 1 0 0 0 0 0 0 ...\n $ VCL9        : int  0 0 0 0 0 1 0 0 0 0 ...\n $ VCL10       : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL11       : int  1 1 1 1 0 1 0 0 0 0 ...\n $ VCL12       : int  0 0 0 0 0 1 0 0 0 0 ...\n $ VCL13       : int  1 0 1 1 1 1 1 0 1 1 ...\n $ VCL14       : int  1 1 1 1 1 1 1 1 1 1 ...\n $ VCL15       : int  1 1 1 0 1 1 1 1 1 1 ...\n $ VCL16       : int  1 1 1 1 1 1 1 1 1 1 ...\n $ education   : int  3 1 4 3 2 3 2 2 1 3 ...\n $ urban       : int  0 2 2 1 2 1 2 1 3 3 ...\n $ gender      : int  1 2 2 1 1 1 1 1 1 1 ...\n $ engnat      : int  2 1 2 1 1 1 1 1 1 2 ...\n $ age         : int  28 14 26 25 37 34 17 23 17 28 ...\n $ hand        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ religion    : int  2 1 1 12 2 7 1 2 4 2 ...\n $ orientation : int  1 2 1 1 2 1 1 1 2 1 ...\n $ race        : int  5 4 4 4 4 4 4 4 4 4 ...\n $ voted       : int  2 2 1 1 2 1 2 2 2 1 ...\n $ married     : int  1 1 1 1 2 2 1 1 1 2 ...\n $ familysize  : int  1 1 2 3 2 2 2 3 2 3 ...\n $ major       : chr  \"ACTING\" \"\" \"philosophy\" \"history\" ...\n\nUsing purrr::nest() along with purrr:map()\nBy looking at the dataset, you can tell it is pretty massive. What if you are interested in how responses differ by gender groups? You probably want to split the data. However, instead of using split() from base r, purrr::nest() can do the same thing.\n\n\nby_gender <- conspiracy %>% \n  group_by(gender) %>% \n  nest()\n\nby_gender\n\n\n# A tibble: 4 x 2\n# Groups:   gender [4]\n  gender data                 \n   <int> <list>               \n1      1 <tibble [1,222 x 71]>\n2      2 <tibble [1,137 x 71]>\n3      3 <tibble [130 x 71]>  \n4      0 <tibble [6 x 71]>    \n\nFrom the output, we can see that the new dataset by_gender contains a list column for each gender. We can play with the list columns a little bit more.\nLet’s say we want to know how many observations were under each gender category.\n\n\nby_gender <- conspiracy %>% \n  group_by(gender) %>% \n  nest() %>% \n  mutate(n = map(data, nrow))\n\nby_gender\n\n\n# A tibble: 4 x 3\n# Groups:   gender [4]\n  gender data                  n        \n   <int> <list>                <list>   \n1      1 <tibble [1,222 x 71]> <int [1]>\n2      2 <tibble [1,137 x 71]> <int [1]>\n3      3 <tibble [130 x 71]>   <int [1]>\n4      0 <tibble [6 x 71]>     <int [1]>\n\nAs you can see, map() returned the number of observations as a list for each gender category, which is not convenient for us to read in order to obtain such simple information. In case like this, variants of map() become handy.\nUsing purrr::map_dbl()\nTo simplify the previous output, we probably want map() to just return us a vector of double (i.e., numeric). It is a good time to use purrr::map_dbl() then.\n\n\nby_gender <- conspiracy %>% \n  group_by(gender) %>% \n  nest() %>% \n  mutate(n = map_dbl(data, nrow))\n\nby_gender\n\n\n# A tibble: 4 x 3\n# Groups:   gender [4]\n  gender data                      n\n   <int> <list>                <dbl>\n1      1 <tibble [1,222 x 71]>  1222\n2      2 <tibble [1,137 x 71]>  1137\n3      3 <tibble [130 x 71]>     130\n4      0 <tibble [6 x 71]>         6\n\nIs it much easier to read now?\nDo some more complex analysis with purrr:map()!\nLet’s say we are interested in the relationship between education (education) and participants’ self ratings for the open to new experiences, complex item (TIPI5). Is the level of education a good predictor of open to new experiences in different gender groups?\n\n\nby_gender <- by_gender %>% \n  mutate(edu_m = map(data, ~lm(TIPI5 ~ education, data = .x)))\n\nby_gender\n\n\n# A tibble: 4 x 4\n# Groups:   gender [4]\n  gender data                      n edu_m \n   <int> <list>                <dbl> <list>\n1      1 <tibble [1,222 x 71]>  1222 <lm>  \n2      2 <tibble [1,137 x 71]>  1137 <lm>  \n3      3 <tibble [130 x 71]>     130 <lm>  \n4      0 <tibble [6 x 71]>         6 <lm>  \n\nWhat about religion (religion) predicting open to new experiences (TIPI5) in different gender groups?\n\n\nby_gender <- by_gender %>% \n  mutate(religion_m = map(data, ~lm(TIPI5 ~ religion, data = .x)))\n\nby_gender\n\n\n# A tibble: 4 x 5\n# Groups:   gender [4]\n  gender data                      n edu_m  religion_m\n   <int> <list>                <dbl> <list> <list>    \n1      1 <tibble [1,222 x 71]>  1222 <lm>   <lm>      \n2      2 <tibble [1,137 x 71]>  1137 <lm>   <lm>      \n3      3 <tibble [130 x 71]>     130 <lm>   <lm>      \n4      0 <tibble [6 x 71]>         6 <lm>   <lm>      \n\nFrom the outputs above, you can see that the results from two liner model are two separate columns, and the result for each gender is wrapped in list column with using mutate() after nest(), but how can do know which variable does better job predict the personality of open to new experiences?\nParallel iteration with purrr::map2()\nAs mentioned previously, map() transforms the input by applying a function to each element of a list or atomic vector. However, {purrr} also provides a function to iterate over two vectors concurrently, purrr::map2(), which takes the following form:\n\n\nmap2(vector1, vector2, a_function/formula/vector, arguments)\n\n\n\nUsing purrr::map2(), we can actually compare between models we created previously!\nJust as you would use stats::anova() to compare two models, we can use stats::anova() within purrr::map2() to compare two list columns of models.\n\n\nmods <- by_gender %>%\n  mutate(\n    edu_m = map(data, ~lm(TIPI5 ~ education, data = .x)),\n    religion_m = map(data, ~lm(TIPI5 ~ religion, data = .x))\n) %>% \n  mutate(comp = map2(edu_m, religion_m, anova))\n\nmods\n\n\n# A tibble: 4 x 6\n# Groups:   gender [4]\n  gender data                      n edu_m  religion_m comp           \n   <int> <list>                <dbl> <list> <list>     <list>         \n1      1 <tibble [1,222 x 71]>  1222 <lm>   <lm>       <anova [2 x 6]>\n2      2 <tibble [1,137 x 71]>  1137 <lm>   <lm>       <anova [2 x 6]>\n3      3 <tibble [130 x 71]>     130 <lm>   <lm>       <anova [2 x 6]>\n4      0 <tibble [6 x 71]>         6 <lm>   <lm>       <anova [2 x 6]>\n\nNow we have model comparison for each gender group with list column! From there, you can extract any information you want.\nThis concludes our tutorial on the purrr::map() family. We hope you had fun with functionals!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-09T15:15:55-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-28-write-a-function/",
    "title": "2. Write a Function!",
    "description": "A tutorial for applying functional programming to personality research",
    "author": [
      {
        "name": "Raleigh Goodwin, Vinita Vader",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [],
    "contents": "\nIntroduction\nIpsatization\nThis is a tutorial on using functional programming to solve specific problems in research. This tutorial addresses the issue of ipsatization, which consists of methods of data transformation used in Personality Psychology and Social Psychology research. Ipsatization transforms each participant’s ratings relative to their average response such that the total and the average of the participant’s scores across all items in the data set are zero (or another constant for all people) (Greer and Dunlap, 1997). In simpler terms, it’s a transformation in which you compute an average response for each participant and then subtract that average from each of their individual responses.\nPackages such as multicon have built functions like ipsatize() which enable standardizing rows of the dataframes being studied. However it does not address the various types of ipsative scorings available for carrying out different transformations.\nAn important aspect of using data transformations involves understanding the relationship between raw data and transformed data. The purpose of the function built here will be to address this specific issue.\nLoading Libraries\nBefore we get started, we need to load the libraries necessary to complete this tutorial. Loading the entire library may not be always necessary, especially if you intend to use it only once. This will be the case for rio, here, and knitr in this tutorial, so you may choose not to load them here if you’d like.\n\n\nlibrary(tidyverse)\nlibrary(purrr)\nlibrary(rio) # optional\nlibrary(here) # optional\nlibrary(knitr) # optional\n\n\n\nAbout the Data\nFor this tutorial, we will be working with a dataset containing the Ten Item Personality Inventory (TIPI; Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr., 2003), a brief measure of the Big Five Personality Domains (Goldberg, 1993). Each item asks respondents to rate themselves on attributes (e.g., extroverted, critical, anxious, calm, etc.) using a Likert scale ranging from 1 to 7, wherein:\n1 = “Disagree strongly”\n2 = “Disagree moderately”\n3 = “Disagree a little”\n4 = “Neither agree nor disagree”\n5 = “Agree a little”\n6 = “Agree moderately”\n7 = “Agree strongly”\nThis particular dataset contains observations from N=2495 individuals who completed, among many other measures, the 10 TIPI items in 2016. Other variables included the Generic Conspiracist Beliefs Scale (Brotherton et al., 2013), various response time metrics, a vocabulary validity check, and demographics.\nImporting the Data\nWhen importing data, two important things to keep in mind are your working directory and reproducibility. Where you save your files can impact the ease at which you can call them; you’ll have the best luck saving data files of interest within the corresponding R Project. rio’s import() function provides an easy method for importing data files, including the ability to set the class of the data to tibble using the setclass argument, which helps to retain the data in a format which is more amenable to data manipulation in tidyverse. To enhance reproducibility across different devices and potentially changing file paths, we’ll use the here() function within the here package when specifying our file path.\n\n\n# Import data\nfull_df <- rio::import(here::here(\"content/dataCT.csv\"), setclass = \"tibble\")\n\n\n\nFor the current project, we’ll only be working with the TIPI items, so to simplify the dataframe we’re using, we can select only those columns.\n\n\n# Select desired variables\ndata <- full_df %>% \n  select(TIPI1:TIPI10)\n\n\n\nNow we can take a look at the data we’ll be working with. The kable() function from the knitr package helps to format the data into a neat table.\n\n\n# Take a look at the data\ndata %>% \n  head(n = 5) %>% # Take a look at the first 5 rows of the resulting dataframe\n  knitr::kable() # Format the output table neatly\n\n\nTIPI1\nTIPI2\nTIPI3\nTIPI4\nTIPI5\nTIPI6\nTIPI7\nTIPI8\nTIPI9\nTIPI10\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n\nAnother package is rmarkdown which can be used for creating neat tables in Distill. The function paged_table() creates a table in its own box on the page.\nWith the libraries loaded and data imported, we can now begin building our function.\nTaking a look at the data\nFirst, though, we can brush off our function-building skills with a simple function to start. In the code above, we used head() to take a look at the data and kable() to format it. We’ll be doing this same process many, many times throughout the tutorial, so it would be a very useful function for us. This function, glance(), will have two arguments: df and nrows, which are the dataframe and the desired number of preview rows, respectively.\n\n\nglance <- function(df, nrows) {\n  df %>% \n    head(n = nrows) %>% \n    knitr::kable()\n}\n\n# Test it out\ndata %>% \n  glance(5)\n\n\nTIPI1\nTIPI2\nTIPI3\nTIPI4\nTIPI5\nTIPI6\nTIPI7\nTIPI8\nTIPI9\nTIPI10\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n\nThis works! If you’d like to read more about functions before continuing, chapter 6 of Hadley Wickham’s Advanced R is an incredibly useful resource. In this tutorial, we will now move on to writing something more complex, walking through an applied case of functional programming within personality research.\nBuilding Functions\nThere are several ways in which one could go about building functions. The approach outlined here should be viewed as one of the several approaches to go about building functions.\nAs you think about building a function, keep in mind the purpose of why you set to build a function in the first place. Your function will ideally solve a problem specific to your analysis or can also be used by others to carry out their analyses.\nLet’s state the problem first: The difference between raw and ipsatized data has been studied to some extent leading to several debates amongst researchers questioning the utility of these methods. It is therefore important to look at correlations between the raw and ipsatized data. With this function, we will perform the ipsatization transformation and correlate its results with the raw data.\nNow that we understand the problem, let’s think about how our function could address this problem. Here are a sequence of questions which will help you think about the function you intend to build.\nWhat is the goal of this function?\nBasically, what do we need this function to do? For the current tutorial, we are writing a function that ipsatizes any dataset, meaning that it will compute the means of the rows and subtract the mean from every score in the respective rows. Ideally, it will produce output in the form of a list containing the raw and transformed (i.e., ipsatized) data, along with a correlation matrix.\nHow can we achieve this goal for a specific dataset?\nWhen taking a functional programming approach to this problem, we should first attempt to solve it within a specific case. Once we’ve done so, we can then consider generalizing to a function. For this tutorial, we will be solving the problem first with the TIPI dataset, and then we can apply that solution to build the final function.\nHow can we break the function’s goal into smaller tasks?\nMost likely, we aren’t just going to be writing one function in this tutorial. Ideally, a function should complete exactly one task; therefore, when we are attempting to build a function to complete a complicated task like ipsatization, we will need to write multiple simple functions and combine them. Thus, it can be helpful to first outline and think through each step of the process and eventually create a function for each step.\nSolving for a specific case\nTo ipsatize the data, we need to calculate each participant’s mean response to the TIPI scale items and then subtract each response by that mean. This means we need to be able to conduct these operations by row rather than by column. One of the easier ways to do this is to use pivot_longer() to transform the data into a “longer” format.\nFirst, though, we need to create an ID for each participant that can then be used to identify their responses once the data is transformed.\n\n\ndata_id <- data %>% \n  mutate(id = c(1:nrow(data))) # Create ID variable\n\ndata_id %>%\n  glance(5)\n\n\nTIPI1\nTIPI2\nTIPI3\nTIPI4\nTIPI5\nTIPI6\nTIPI7\nTIPI8\nTIPI9\nTIPI10\nid\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n1\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n2\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n3\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n4\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n5\n\nNow that we have an ID variable that can be used to identify each participant’s responses, we can figure out how to create a column that calculates the mean of each rows using pivot_longer().\n\n\ndata_long <- data_id %>% \n  pivot_longer(cols = !id, names_to = \"item\", values_to = \"response\")\n\ndata_long %>% \n  glance(15)\n\n\nid\nitem\nresponse\n1\nTIPI1\n5\n1\nTIPI2\n3\n1\nTIPI3\n6\n1\nTIPI4\n2\n1\nTIPI5\n6\n1\nTIPI6\n6\n1\nTIPI7\n7\n1\nTIPI8\n2\n1\nTIPI9\n7\n1\nTIPI10\n1\n2\nTIPI1\n6\n2\nTIPI2\n7\n2\nTIPI3\n6\n2\nTIPI4\n7\n2\nTIPI5\n6\n\nInstead of participants’ responses being organized by row, all responses are now contained in one column and can be identified using the corresponding ID and Item values. We can use tidyverse’s group_by() function to group this dataframe by participant ID and then compute 1) the mean for each group and 2) the difference between each response and the mean of its group.\n\n\ndata_dev <- data_long %>% \n  group_by(id) %>% # Group by participant ID\n  mutate(mean_row = mean(response, na.rm = TRUE), # Calculate participant mean\n         ipsatized = response - mean_row) # Calculate individual response deviation from mean\n\ndata_dev %>% \n  glance(15)\n\n\nid\nitem\nresponse\nmean_row\nipsatized\n1\nTIPI1\n5\n4.5\n0.5\n1\nTIPI2\n3\n4.5\n-1.5\n1\nTIPI3\n6\n4.5\n1.5\n1\nTIPI4\n2\n4.5\n-2.5\n1\nTIPI5\n6\n4.5\n1.5\n1\nTIPI6\n6\n4.5\n1.5\n1\nTIPI7\n7\n4.5\n2.5\n1\nTIPI8\n2\n4.5\n-2.5\n1\nTIPI9\n7\n4.5\n2.5\n1\nTIPI10\n1\n4.5\n-3.5\n2\nTIPI1\n6\n4.9\n1.1\n2\nTIPI2\n7\n4.9\n2.1\n2\nTIPI3\n6\n4.9\n1.1\n2\nTIPI4\n7\n4.9\n2.1\n2\nTIPI5\n6\n4.9\n1.1\n\nNow, we can use pivot_wider() to transform the data back to its original format. Because we want the function output to be formatted as a list that contains the ipsatized data, raw data, and a correlation matrix of the two, it will be helpful to create two dataframes: an ipsatized dataframe and a raw dataframe.\n\n\n# Create ipsatized data frame\ndata_ips <- data_dev %>%\n  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%\n  select(id, contains(\"ipsatized\")) %>%\n   ungroup()\n\n# Create raw dataframe\ndata_raw <- data_dev %>%\n  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%\n  select(id, contains(\"response\")) %>%\n   ungroup()\n\n# Take a look at the results\ndata_ips %>% \n  glance(15)\n\n\nid\nipsatized_TIPI1\nipsatized_TIPI2\nipsatized_TIPI3\nipsatized_TIPI4\nipsatized_TIPI5\nipsatized_TIPI6\nipsatized_TIPI7\nipsatized_TIPI8\nipsatized_TIPI9\nipsatized_TIPI10\n1\n0.5\n-1.5\n1.5\n-2.5\n1.5\n1.5\n2.5\n-2.5\n2.5\n-3.5\n2\n1.1\n2.1\n1.1\n2.1\n1.1\n-1.9\n2.1\n0.1\n-3.9\n-3.9\n3\n0.4\n0.4\n0.4\n-4.6\n1.4\n-0.6\n0.4\n-0.6\n1.4\n1.4\n4\n1.0\n2.0\n2.0\n0.0\n2.0\n1.0\n0.0\n-4.0\n0.0\n-4.0\n5\n-3.1\n-1.1\n2.9\n-2.1\n1.9\n-0.1\n0.9\n0.9\n0.9\n-1.1\n6\n-0.2\n-2.2\n1.8\n-2.2\n1.8\n0.8\n1.8\n-1.2\n1.8\n-2.2\n7\n-1.9\n1.1\n0.1\n-1.9\n1.1\n2.1\n-1.9\n-0.9\n1.1\n1.1\n8\n-0.2\n0.8\n1.8\n-2.2\n2.8\n-0.2\n0.8\n0.8\n-1.2\n-3.2\n9\n-0.3\n0.7\n1.7\n-2.3\n-0.3\n0.7\n1.7\n-2.3\n2.7\n-2.3\n10\n-3.5\n1.5\n-1.5\n-3.5\n0.5\n2.5\n1.5\n0.5\n2.5\n-0.5\n11\n-0.3\n3.7\n-2.3\n3.7\n3.7\n-0.3\n-2.3\n-1.3\n-2.3\n-2.3\n12\n2.2\n-0.8\n-0.8\n-3.8\n2.2\n-0.8\n2.2\n0.2\n2.2\n-2.8\n13\n1.6\n-2.4\n1.6\n-3.4\n1.6\n0.6\n2.6\n-0.4\n0.6\n-2.4\n14\n-2.8\n-2.8\n1.2\n0.2\n2.2\n1.2\n2.2\n0.2\n1.2\n-2.8\n15\n-2.7\n-2.7\n-2.7\n2.3\n1.3\n3.3\n3.3\n3.3\n-2.7\n-2.7\n\ndata_raw %>% \n  glance(15)\n\n\nid\nresponse_TIPI1\nresponse_TIPI2\nresponse_TIPI3\nresponse_TIPI4\nresponse_TIPI5\nresponse_TIPI6\nresponse_TIPI7\nresponse_TIPI8\nresponse_TIPI9\nresponse_TIPI10\n1\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n2\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n3\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n4\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n5\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n6\n4\n2\n6\n2\n6\n5\n6\n3\n6\n2\n7\n2\n5\n4\n2\n5\n6\n2\n3\n5\n5\n8\n4\n5\n6\n2\n7\n4\n5\n5\n3\n1\n9\n4\n5\n6\n2\n4\n5\n6\n2\n7\n2\n10\n1\n6\n3\n1\n5\n7\n6\n5\n7\n4\n11\n3\n7\n1\n7\n7\n3\n1\n2\n1\n1\n12\n7\n4\n4\n1\n7\n4\n7\n5\n7\n2\n13\n6\n2\n6\n1\n6\n5\n7\n4\n5\n2\n14\n2\n2\n6\n5\n7\n6\n7\n5\n6\n2\n15\n1\n1\n1\n6\n5\n7\n7\n7\n1\n1\n\nLastly, let’s create that list.\n\n\nlist_output <- list(\"ipsatized\" = data_ips,\n          \"raw\" = data_raw,\n          \"correlation_matrix\" = cor(data_ips, data_raw))\n\nlist_output\n\n\n$ipsatized\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\n$correlation_matrix\n                           id response_TIPI1 response_TIPI2\nid                1.000000000    -0.03087740    -0.03727441\nipsatized_TIPI1  -0.021481713     0.95997515    -0.11340834\nipsatized_TIPI2  -0.027501605    -0.12071784     0.95428074\nipsatized_TIPI3  -0.036290745     0.02535938    -0.16688353\nipsatized_TIPI4   0.022218869    -0.25970548     0.12817941\nipsatized_TIPI5   0.017044441     0.15867518    -0.13509164\nipsatized_TIPI6   0.033065029    -0.68318241    -0.07328539\nipsatized_TIPI7   0.021550310     0.19604318    -0.39102208\nipsatized_TIPI8   0.028246853    -0.09883568     0.05362126\nipsatized_TIPI9  -0.029634489     0.06676858    -0.27632275\nipsatized_TIPI10 -0.005017054    -0.22041641    -0.06129857\n                 response_TIPI3 response_TIPI4 response_TIPI5\nid                 -0.045915845    0.011284963   0.0008224971\nipsatized_TIPI1     0.031167709   -0.244068520   0.1736167712\nipsatized_TIPI2    -0.167224238    0.148187176  -0.1206510887\nipsatized_TIPI3     0.948872899   -0.298764735   0.0086683433\nipsatized_TIPI4    -0.307516250    0.962139678  -0.2550686241\nipsatized_TIPI5    -0.005073157   -0.256663167   0.9192189953\nipsatized_TIPI6    -0.024670231    0.073760081  -0.2270060851\nipsatized_TIPI7     0.007475973   -0.008942264   0.0736922080\nipsatized_TIPI8    -0.550478491    0.158821663  -0.0270662628\nipsatized_TIPI9     0.268938383   -0.690397982   0.0655434271\nipsatized_TIPI10   -0.108530999   -0.002177791  -0.3767678405\n                 response_TIPI6 response_TIPI7 response_TIPI8\nid                  0.021000522    0.007644219     0.01618021\nipsatized_TIPI1    -0.666541441    0.170445729    -0.08266381\nipsatized_TIPI2    -0.038939637   -0.403279907     0.06565301\nipsatized_TIPI3     0.015568018   -0.020080341    -0.54989652\nipsatized_TIPI4     0.091005873   -0.050084957     0.15131155\nipsatized_TIPI5    -0.203227013    0.024189448    -0.02356731\nipsatized_TIPI6     0.953180313   -0.215281446    -0.08954131\nipsatized_TIPI7    -0.162399055    0.949232042    -0.08558253\nipsatized_TIPI8    -0.067303304   -0.119072017     0.95695523\nipsatized_TIPI9    -0.009290563   -0.028893032    -0.33029253\nipsatized_TIPI10    0.040201343   -0.228842712    -0.10619799\n                 response_TIPI9 response_TIPI10\nid                  -0.03949432    -0.017594425\nipsatized_TIPI1      0.09172718    -0.187414036\nipsatized_TIPI2     -0.26483551    -0.031356832\nipsatized_TIPI3      0.29771049    -0.076414836\nipsatized_TIPI4     -0.68790076     0.007123348\nipsatized_TIPI5      0.08228079    -0.365950413\nipsatized_TIPI6     -0.02645471     0.029629981\nipsatized_TIPI7      0.01615832    -0.176200329\nipsatized_TIPI8     -0.32648284    -0.089488624\nipsatized_TIPI9      0.95761526    -0.057303325\nipsatized_TIPI10    -0.06741043     0.941250723\n\nThis list is what we set out to create! We’ve achieved our goal using this dataset.\nNow that we’ve solved this problem in a specific case, we can begin to generalize it to a function. Or, rather, a set of functions!\nApplying specific case to generalized function(s)\nSince we want each function to only do one task, we can first outline the individual tasks that make up the ipsatization process.\nAdd an ID variable to the dataframe\nPivot the data to a longer format\nCalculate the mean of each row and transform each response by subtracting the row mean from it\nPivot the data back to a wider format\nCreate a list to organize the output\nNow we can set out to make a function to complete each task. These functions don’t ever have to be used on their own; in the end, they’ll all be combined into a final, single function. This may seem like it’s making work more complicated, but this approach enhances readability of your code and aids in troubleshooting errors.\nSince we’ve done the majority of the problem solving already, we can essentially copy and paste our code from above, making sure to adapt as necessary to the function format. Luckily, for the current tutorial, these changes mostly consist of changing the name of the dataframe input to “df,” which is the name of our only argument in this function.\nAfter we build each function, we can test that it works by running it with a couple of datasets. Since we wrote this code with the TIPI dataset in mind, we can also test it with another dataset in order to catch any potential issues that may crop up when using different data. Though ipsatization is typically used in personality research, we’ll use the iris dataset as our second test case for simplicity.\nAdd an ID variable to the dataframe\n\n\nadd_id <- function(df) {\n  df %>%\n    mutate(id = c(1:nrow(df)))\n}\n\n\n\n\n\n# Test it out\ntest1 <- data %>% \n  add_id()\n\ntest2 <- iris %>% \n  add_id()\n\ntest1 %>%  \n  glance(5)\n\n\nTIPI1\nTIPI2\nTIPI3\nTIPI4\nTIPI5\nTIPI6\nTIPI7\nTIPI8\nTIPI9\nTIPI10\nid\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n1\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n2\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n3\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n4\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n5\n\ntest2 %>%  \n  glance(5)\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\nid\n5.1\n3.5\n1.4\n0.2\nsetosa\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n5\n\nIt works! However, when looking at the output for the dataframe iris, you may notice a difference between it and the specific case in which we originally wrote this code: This dataset contains character data in addition to numeric data. Before we go any further, we have to write code that extracts only numeric columns from the dataframe of interest.\n1.5. Select only numeric columns from dataframe\nWe can accomplish this using the map_lgl() function from the purrr package, which maps the is.numeric() function to every column in the dataframe and is appropriate in this case because the output will be a logical vector. This will ensure that all the columns in the dataframe we are working with are numeric.\nFor more information about the purrr::map() family, see our first post.\nFirst, we can try writing this code to solve the problem in the iris dataset specifically.\n\n\niris[ , purrr::map_lgl(iris, is.numeric)] %>% \n  glance(10)\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\n5.1\n3.5\n1.4\n0.2\n4.9\n3.0\n1.4\n0.2\n4.7\n3.2\n1.3\n0.2\n4.6\n3.1\n1.5\n0.2\n5.0\n3.6\n1.4\n0.2\n5.4\n3.9\n1.7\n0.4\n4.6\n3.4\n1.4\n0.3\n5.0\n3.4\n1.5\n0.2\n4.4\n2.9\n1.4\n0.2\n4.9\n3.1\n1.5\n0.1\n\nJust like before, we can now translate that code into a function. This time, we’ll also add a condition to our function: If there are no numeric columns in the dataset (i.e., if the sum of all possible numeric columns is 0), the loop will stop and the function will throw an error message. If there is at least one numeric column, the function will run as normal.\n\n\njust_num <- function(df) {\n  if(sum(purrr::map_lgl(df, is.numeric)) == 0) {\n    stop(\"No numeric columns.\")\n  }\n    else{\n      df1 <- df[ , purrr::map_lgl(df, is.numeric)]\n      df1\n    }\n}\n\n\n\n\n\n# Test it out\ntest1 <- test1 %>% \n  just_num()\n\ntest2 <- test2 %>% \n  just_num()\n\ntest1 %>% \n  glance(15)\n\n\nTIPI1\nTIPI2\nTIPI3\nTIPI4\nTIPI5\nTIPI6\nTIPI7\nTIPI8\nTIPI9\nTIPI10\nid\n5\n3\n6\n2\n6\n6\n7\n2\n7\n1\n1\n6\n7\n6\n7\n6\n3\n7\n5\n1\n1\n2\n6\n6\n6\n1\n7\n5\n6\n5\n7\n7\n3\n6\n7\n7\n5\n7\n6\n5\n1\n5\n1\n4\n1\n3\n7\n2\n6\n4\n5\n5\n5\n3\n5\n4\n2\n6\n2\n6\n5\n6\n3\n6\n2\n6\n2\n5\n4\n2\n5\n6\n2\n3\n5\n5\n7\n4\n5\n6\n2\n7\n4\n5\n5\n3\n1\n8\n4\n5\n6\n2\n4\n5\n6\n2\n7\n2\n9\n1\n6\n3\n1\n5\n7\n6\n5\n7\n4\n10\n3\n7\n1\n7\n7\n3\n1\n2\n1\n1\n11\n7\n4\n4\n1\n7\n4\n7\n5\n7\n2\n12\n6\n2\n6\n1\n6\n5\n7\n4\n5\n2\n13\n2\n2\n6\n5\n7\n6\n7\n5\n6\n2\n14\n1\n1\n1\n6\n5\n7\n7\n7\n1\n1\n15\n\ntest2 %>% \n  glance(15)\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nid\n5.1\n3.5\n1.4\n0.2\n1\n4.9\n3.0\n1.4\n0.2\n2\n4.7\n3.2\n1.3\n0.2\n3\n4.6\n3.1\n1.5\n0.2\n4\n5.0\n3.6\n1.4\n0.2\n5\n5.4\n3.9\n1.7\n0.4\n6\n4.6\n3.4\n1.4\n0.3\n7\n5.0\n3.4\n1.5\n0.2\n8\n4.4\n2.9\n1.4\n0.2\n9\n4.9\n3.1\n1.5\n0.1\n10\n5.4\n3.7\n1.5\n0.2\n11\n4.8\n3.4\n1.6\n0.2\n12\n4.8\n3.0\n1.4\n0.1\n13\n4.3\n3.0\n1.1\n0.1\n14\n5.8\n4.0\n1.2\n0.2\n15\n\nTo test our condition, we should also test this function with a dataset that has no numeric columns.\n\n\ntest3 <- tibble(letters, LETTERS)\n\ntest3 %>% \n  glance(5)\n\n\nletters\nLETTERS\na\nA\nb\nB\nc\nC\nd\nD\ne\nE\n\nWhen doing so, we can also explore the utility of the safely() function from purrr. If we use just_num() on test3 and it throws the correct error, we will not be able to knit this document. safely() allows you to create “safe” functions that will return output that also “captures” errors, which would normally stop a function from being able to run. This can be very useful for troubleshooting and will help us test our function on test3.\n\n\n# Test it out with `safely()`\nsafe_just_num <- purrr::safely(just_num)\n\ntest3 %>% \n  safe_just_num()\n\n\n$result\nNULL\n\n$error\n<simpleError in .f(...): No numeric columns.>\n\n# vs:\n\ntest4 <- tibble(1:5, 6:10)\n\ntest4 %>% \n  safe_just_num()\n\n\n$result\n# A tibble: 5 x 2\n  `1:5` `6:10`\n  <int>  <int>\n1     1      6\n2     2      7\n3     3      8\n4     4      9\n5     5     10\n\n$error\nNULL\n\nCritically, this function will allow our final function to generalize to multiple different datasets. With that done, we can continue with the rest of our outlined tasks.\nPivot the data to a longer format\n\n\nlengthen_data <- function(df) {\n  df %>% \n  pivot_longer(cols = !id, names_to = \"item\", values_to = \"response\")\n}\n\n\n\n\n\n# Test it out\ntest1 <- test1 %>% \n  lengthen_data()\n\ntest2 <- test2 %>% \n  lengthen_data()\n\ntest1 %>% \n  glance(15)\n\n\nid\nitem\nresponse\n1\nTIPI1\n5\n1\nTIPI2\n3\n1\nTIPI3\n6\n1\nTIPI4\n2\n1\nTIPI5\n6\n1\nTIPI6\n6\n1\nTIPI7\n7\n1\nTIPI8\n2\n1\nTIPI9\n7\n1\nTIPI10\n1\n2\nTIPI1\n6\n2\nTIPI2\n7\n2\nTIPI3\n6\n2\nTIPI4\n7\n2\nTIPI5\n6\n\ntest2 %>% \n  glance(15)\n\n\nid\nitem\nresponse\n1\nSepal.Length\n5.1\n1\nSepal.Width\n3.5\n1\nPetal.Length\n1.4\n1\nPetal.Width\n0.2\n2\nSepal.Length\n4.9\n2\nSepal.Width\n3.0\n2\nPetal.Length\n1.4\n2\nPetal.Width\n0.2\n3\nSepal.Length\n4.7\n3\nSepal.Width\n3.2\n3\nPetal.Length\n1.3\n3\nPetal.Width\n0.2\n4\nSepal.Length\n4.6\n4\nSepal.Width\n3.1\n4\nPetal.Length\n1.5\n\nCalculate the mean of each row and transform each response by subtracting the row mean from it\n\n\ntransform_data <- function(df) {\n  df %>% \n  group_by(id) %>% # Group by participant ID\n  mutate(mean_row = mean(response, na.rm = TRUE), # Calculate participant mean\n         ipsatized = response - mean_row) # Calculate individual response deviation from mean\n}\n\n\n\n\n\n# Test it out\ntest1 <- test1 %>% \n  transform_data()\n\ntest2 <- test2 %>% \n  transform_data()\n\ntest1 %>% \n  glance(15)\n\n\nid\nitem\nresponse\nmean_row\nipsatized\n1\nTIPI1\n5\n4.5\n0.5\n1\nTIPI2\n3\n4.5\n-1.5\n1\nTIPI3\n6\n4.5\n1.5\n1\nTIPI4\n2\n4.5\n-2.5\n1\nTIPI5\n6\n4.5\n1.5\n1\nTIPI6\n6\n4.5\n1.5\n1\nTIPI7\n7\n4.5\n2.5\n1\nTIPI8\n2\n4.5\n-2.5\n1\nTIPI9\n7\n4.5\n2.5\n1\nTIPI10\n1\n4.5\n-3.5\n2\nTIPI1\n6\n4.9\n1.1\n2\nTIPI2\n7\n4.9\n2.1\n2\nTIPI3\n6\n4.9\n1.1\n2\nTIPI4\n7\n4.9\n2.1\n2\nTIPI5\n6\n4.9\n1.1\n\ntest2 %>% \n  glance(15)\n\n\nid\nitem\nresponse\nmean_row\nipsatized\n1\nSepal.Length\n5.1\n2.550\n2.550\n1\nSepal.Width\n3.5\n2.550\n0.950\n1\nPetal.Length\n1.4\n2.550\n-1.150\n1\nPetal.Width\n0.2\n2.550\n-2.350\n2\nSepal.Length\n4.9\n2.375\n2.525\n2\nSepal.Width\n3.0\n2.375\n0.625\n2\nPetal.Length\n1.4\n2.375\n-0.975\n2\nPetal.Width\n0.2\n2.375\n-2.175\n3\nSepal.Length\n4.7\n2.350\n2.350\n3\nSepal.Width\n3.2\n2.350\n0.850\n3\nPetal.Length\n1.3\n2.350\n-1.050\n3\nPetal.Width\n0.2\n2.350\n-2.150\n4\nSepal.Length\n4.6\n2.350\n2.250\n4\nSepal.Width\n3.1\n2.350\n0.750\n4\nPetal.Length\n1.5\n2.350\n-0.850\n\nPivot the data back to a wider format\n\n\nwiden_data <- function(df) {\n  # Create ipsatized data frame\ndata_ips_id <- df %>%\n  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%\n  select(id, contains(\"ipsatized\")) %>%\n   ungroup()\n\n# Create raw dataframe\ndata_raw_id <- df %>%\n  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%\n  select(id, contains(\"response\")) %>%\n   ungroup()\n\n# Functions don't return multiple objects, so we have to wrap them into a single list\noutputlist <- list(\"data_ips\" = data_ips, \n                   \"data_raw\" = data_raw)\n\n# Return list\nreturn(outputlist)\n}\n\n\n\n\n\n# Test it out\ntest1 <- test1 %>% \n  widen_data()\n\ntest2 <- test2 %>% \n  widen_data()\n\ntest1\n\n\n$data_ips\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$data_raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\ntest2\n\n\n$data_ips\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$data_raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\nCreate a list to organize the desired, final output\n\n\nipsatize_list <- function(df) {\n  list(\"ipsatized\" = df$data_ips,\n          \"raw\" = df$data_raw,\n          \"correlation_matrix\" = cor(df$data_ips, df$data_raw))\n}\n\n\n\n\n\n# Test it out\ntest1 %>%\n  ipsatize_list()\n\n\n$ipsatized\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\n$correlation_matrix\n                           id response_TIPI1 response_TIPI2\nid                1.000000000    -0.03087740    -0.03727441\nipsatized_TIPI1  -0.021481713     0.95997515    -0.11340834\nipsatized_TIPI2  -0.027501605    -0.12071784     0.95428074\nipsatized_TIPI3  -0.036290745     0.02535938    -0.16688353\nipsatized_TIPI4   0.022218869    -0.25970548     0.12817941\nipsatized_TIPI5   0.017044441     0.15867518    -0.13509164\nipsatized_TIPI6   0.033065029    -0.68318241    -0.07328539\nipsatized_TIPI7   0.021550310     0.19604318    -0.39102208\nipsatized_TIPI8   0.028246853    -0.09883568     0.05362126\nipsatized_TIPI9  -0.029634489     0.06676858    -0.27632275\nipsatized_TIPI10 -0.005017054    -0.22041641    -0.06129857\n                 response_TIPI3 response_TIPI4 response_TIPI5\nid                 -0.045915845    0.011284963   0.0008224971\nipsatized_TIPI1     0.031167709   -0.244068520   0.1736167712\nipsatized_TIPI2    -0.167224238    0.148187176  -0.1206510887\nipsatized_TIPI3     0.948872899   -0.298764735   0.0086683433\nipsatized_TIPI4    -0.307516250    0.962139678  -0.2550686241\nipsatized_TIPI5    -0.005073157   -0.256663167   0.9192189953\nipsatized_TIPI6    -0.024670231    0.073760081  -0.2270060851\nipsatized_TIPI7     0.007475973   -0.008942264   0.0736922080\nipsatized_TIPI8    -0.550478491    0.158821663  -0.0270662628\nipsatized_TIPI9     0.268938383   -0.690397982   0.0655434271\nipsatized_TIPI10   -0.108530999   -0.002177791  -0.3767678405\n                 response_TIPI6 response_TIPI7 response_TIPI8\nid                  0.021000522    0.007644219     0.01618021\nipsatized_TIPI1    -0.666541441    0.170445729    -0.08266381\nipsatized_TIPI2    -0.038939637   -0.403279907     0.06565301\nipsatized_TIPI3     0.015568018   -0.020080341    -0.54989652\nipsatized_TIPI4     0.091005873   -0.050084957     0.15131155\nipsatized_TIPI5    -0.203227013    0.024189448    -0.02356731\nipsatized_TIPI6     0.953180313   -0.215281446    -0.08954131\nipsatized_TIPI7    -0.162399055    0.949232042    -0.08558253\nipsatized_TIPI8    -0.067303304   -0.119072017     0.95695523\nipsatized_TIPI9    -0.009290563   -0.028893032    -0.33029253\nipsatized_TIPI10    0.040201343   -0.228842712    -0.10619799\n                 response_TIPI9 response_TIPI10\nid                  -0.03949432    -0.017594425\nipsatized_TIPI1      0.09172718    -0.187414036\nipsatized_TIPI2     -0.26483551    -0.031356832\nipsatized_TIPI3      0.29771049    -0.076414836\nipsatized_TIPI4     -0.68790076     0.007123348\nipsatized_TIPI5      0.08228079    -0.365950413\nipsatized_TIPI6     -0.02645471     0.029629981\nipsatized_TIPI7      0.01615832    -0.176200329\nipsatized_TIPI8     -0.32648284    -0.089488624\nipsatized_TIPI9      0.95761526    -0.057303325\nipsatized_TIPI10    -0.06741043     0.941250723\n\ntest2 %>%\n  ipsatize_list()\n\n\n$ipsatized\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\n$correlation_matrix\n                           id response_TIPI1 response_TIPI2\nid                1.000000000    -0.03087740    -0.03727441\nipsatized_TIPI1  -0.021481713     0.95997515    -0.11340834\nipsatized_TIPI2  -0.027501605    -0.12071784     0.95428074\nipsatized_TIPI3  -0.036290745     0.02535938    -0.16688353\nipsatized_TIPI4   0.022218869    -0.25970548     0.12817941\nipsatized_TIPI5   0.017044441     0.15867518    -0.13509164\nipsatized_TIPI6   0.033065029    -0.68318241    -0.07328539\nipsatized_TIPI7   0.021550310     0.19604318    -0.39102208\nipsatized_TIPI8   0.028246853    -0.09883568     0.05362126\nipsatized_TIPI9  -0.029634489     0.06676858    -0.27632275\nipsatized_TIPI10 -0.005017054    -0.22041641    -0.06129857\n                 response_TIPI3 response_TIPI4 response_TIPI5\nid                 -0.045915845    0.011284963   0.0008224971\nipsatized_TIPI1     0.031167709   -0.244068520   0.1736167712\nipsatized_TIPI2    -0.167224238    0.148187176  -0.1206510887\nipsatized_TIPI3     0.948872899   -0.298764735   0.0086683433\nipsatized_TIPI4    -0.307516250    0.962139678  -0.2550686241\nipsatized_TIPI5    -0.005073157   -0.256663167   0.9192189953\nipsatized_TIPI6    -0.024670231    0.073760081  -0.2270060851\nipsatized_TIPI7     0.007475973   -0.008942264   0.0736922080\nipsatized_TIPI8    -0.550478491    0.158821663  -0.0270662628\nipsatized_TIPI9     0.268938383   -0.690397982   0.0655434271\nipsatized_TIPI10   -0.108530999   -0.002177791  -0.3767678405\n                 response_TIPI6 response_TIPI7 response_TIPI8\nid                  0.021000522    0.007644219     0.01618021\nipsatized_TIPI1    -0.666541441    0.170445729    -0.08266381\nipsatized_TIPI2    -0.038939637   -0.403279907     0.06565301\nipsatized_TIPI3     0.015568018   -0.020080341    -0.54989652\nipsatized_TIPI4     0.091005873   -0.050084957     0.15131155\nipsatized_TIPI5    -0.203227013    0.024189448    -0.02356731\nipsatized_TIPI6     0.953180313   -0.215281446    -0.08954131\nipsatized_TIPI7    -0.162399055    0.949232042    -0.08558253\nipsatized_TIPI8    -0.067303304   -0.119072017     0.95695523\nipsatized_TIPI9    -0.009290563   -0.028893032    -0.33029253\nipsatized_TIPI10    0.040201343   -0.228842712    -0.10619799\n                 response_TIPI9 response_TIPI10\nid                  -0.03949432    -0.017594425\nipsatized_TIPI1      0.09172718    -0.187414036\nipsatized_TIPI2     -0.26483551    -0.031356832\nipsatized_TIPI3      0.29771049    -0.076414836\nipsatized_TIPI4     -0.68790076     0.007123348\nipsatized_TIPI5      0.08228079    -0.365950413\nipsatized_TIPI6     -0.02645471     0.029629981\nipsatized_TIPI7      0.01615832    -0.176200329\nipsatized_TIPI8     -0.32648284    -0.089488624\nipsatized_TIPI9      0.95761526    -0.057303325\nipsatized_TIPI10    -0.06741043     0.941250723\n\nNow let’s combine all of these functions together!\n\n\nipsatize <- function(df) {\n  df %>% \n    just_num() %>% \n    add_id() %>% \n    lengthen_data() %>% \n    transform_data() %>% \n    widen_data() %>% \n    ipsatize_list()\n}\n\n\n\n\n\n# Test it out\nipsatize(data)\n\n\n$ipsatized\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\n$correlation_matrix\n                           id response_TIPI1 response_TIPI2\nid                1.000000000    -0.03087740    -0.03727441\nipsatized_TIPI1  -0.021481713     0.95997515    -0.11340834\nipsatized_TIPI2  -0.027501605    -0.12071784     0.95428074\nipsatized_TIPI3  -0.036290745     0.02535938    -0.16688353\nipsatized_TIPI4   0.022218869    -0.25970548     0.12817941\nipsatized_TIPI5   0.017044441     0.15867518    -0.13509164\nipsatized_TIPI6   0.033065029    -0.68318241    -0.07328539\nipsatized_TIPI7   0.021550310     0.19604318    -0.39102208\nipsatized_TIPI8   0.028246853    -0.09883568     0.05362126\nipsatized_TIPI9  -0.029634489     0.06676858    -0.27632275\nipsatized_TIPI10 -0.005017054    -0.22041641    -0.06129857\n                 response_TIPI3 response_TIPI4 response_TIPI5\nid                 -0.045915845    0.011284963   0.0008224971\nipsatized_TIPI1     0.031167709   -0.244068520   0.1736167712\nipsatized_TIPI2    -0.167224238    0.148187176  -0.1206510887\nipsatized_TIPI3     0.948872899   -0.298764735   0.0086683433\nipsatized_TIPI4    -0.307516250    0.962139678  -0.2550686241\nipsatized_TIPI5    -0.005073157   -0.256663167   0.9192189953\nipsatized_TIPI6    -0.024670231    0.073760081  -0.2270060851\nipsatized_TIPI7     0.007475973   -0.008942264   0.0736922080\nipsatized_TIPI8    -0.550478491    0.158821663  -0.0270662628\nipsatized_TIPI9     0.268938383   -0.690397982   0.0655434271\nipsatized_TIPI10   -0.108530999   -0.002177791  -0.3767678405\n                 response_TIPI6 response_TIPI7 response_TIPI8\nid                  0.021000522    0.007644219     0.01618021\nipsatized_TIPI1    -0.666541441    0.170445729    -0.08266381\nipsatized_TIPI2    -0.038939637   -0.403279907     0.06565301\nipsatized_TIPI3     0.015568018   -0.020080341    -0.54989652\nipsatized_TIPI4     0.091005873   -0.050084957     0.15131155\nipsatized_TIPI5    -0.203227013    0.024189448    -0.02356731\nipsatized_TIPI6     0.953180313   -0.215281446    -0.08954131\nipsatized_TIPI7    -0.162399055    0.949232042    -0.08558253\nipsatized_TIPI8    -0.067303304   -0.119072017     0.95695523\nipsatized_TIPI9    -0.009290563   -0.028893032    -0.33029253\nipsatized_TIPI10    0.040201343   -0.228842712    -0.10619799\n                 response_TIPI9 response_TIPI10\nid                  -0.03949432    -0.017594425\nipsatized_TIPI1      0.09172718    -0.187414036\nipsatized_TIPI2     -0.26483551    -0.031356832\nipsatized_TIPI3      0.29771049    -0.076414836\nipsatized_TIPI4     -0.68790076     0.007123348\nipsatized_TIPI5      0.08228079    -0.365950413\nipsatized_TIPI6     -0.02645471     0.029629981\nipsatized_TIPI7      0.01615832    -0.176200329\nipsatized_TIPI8     -0.32648284    -0.089488624\nipsatized_TIPI9      0.95761526    -0.057303325\nipsatized_TIPI10    -0.06741043     0.941250723\n\nipsatize(iris)\n\n\n$ipsatized\n# A tibble: 2,495 x 11\n      id ipsatized_TIPI1 ipsatized_TIPI2 ipsatized_TIPI3\n   <int>           <dbl>           <dbl>           <dbl>\n 1     1           0.5            -1.5              1.5 \n 2     2           1.10            2.10             1.10\n 3     3           0.4             0.4              0.4 \n 4     4           1               2                2   \n 5     5          -3.10           -1.10             2.9 \n 6     6          -0.2            -2.2              1.8 \n 7     7          -1.9             1.1              0.1 \n 8     8          -0.2             0.800            1.8 \n 9     9          -0.300           0.7              1.7 \n10    10          -3.5             1.5             -1.5 \n# … with 2,485 more rows, and 7 more variables:\n#   ipsatized_TIPI4 <dbl>, ipsatized_TIPI5 <dbl>,\n#   ipsatized_TIPI6 <dbl>, ipsatized_TIPI7 <dbl>,\n#   ipsatized_TIPI8 <dbl>, ipsatized_TIPI9 <dbl>,\n#   ipsatized_TIPI10 <dbl>\n\n$raw\n# A tibble: 2,495 x 11\n      id response_TIPI1 response_TIPI2 response_TIPI3 response_TIPI4\n   <int>          <int>          <int>          <int>          <int>\n 1     1              5              3              6              2\n 2     2              6              7              6              7\n 3     3              6              6              6              1\n 4     4              6              7              7              5\n 5     5              1              3              7              2\n 6     6              4              2              6              2\n 7     7              2              5              4              2\n 8     8              4              5              6              2\n 9     9              4              5              6              2\n10    10              1              6              3              1\n# … with 2,485 more rows, and 6 more variables: response_TIPI5 <int>,\n#   response_TIPI6 <int>, response_TIPI7 <int>, response_TIPI8 <int>,\n#   response_TIPI9 <int>, response_TIPI10 <int>\n\n$correlation_matrix\n                           id response_TIPI1 response_TIPI2\nid                1.000000000    -0.03087740    -0.03727441\nipsatized_TIPI1  -0.021481713     0.95997515    -0.11340834\nipsatized_TIPI2  -0.027501605    -0.12071784     0.95428074\nipsatized_TIPI3  -0.036290745     0.02535938    -0.16688353\nipsatized_TIPI4   0.022218869    -0.25970548     0.12817941\nipsatized_TIPI5   0.017044441     0.15867518    -0.13509164\nipsatized_TIPI6   0.033065029    -0.68318241    -0.07328539\nipsatized_TIPI7   0.021550310     0.19604318    -0.39102208\nipsatized_TIPI8   0.028246853    -0.09883568     0.05362126\nipsatized_TIPI9  -0.029634489     0.06676858    -0.27632275\nipsatized_TIPI10 -0.005017054    -0.22041641    -0.06129857\n                 response_TIPI3 response_TIPI4 response_TIPI5\nid                 -0.045915845    0.011284963   0.0008224971\nipsatized_TIPI1     0.031167709   -0.244068520   0.1736167712\nipsatized_TIPI2    -0.167224238    0.148187176  -0.1206510887\nipsatized_TIPI3     0.948872899   -0.298764735   0.0086683433\nipsatized_TIPI4    -0.307516250    0.962139678  -0.2550686241\nipsatized_TIPI5    -0.005073157   -0.256663167   0.9192189953\nipsatized_TIPI6    -0.024670231    0.073760081  -0.2270060851\nipsatized_TIPI7     0.007475973   -0.008942264   0.0736922080\nipsatized_TIPI8    -0.550478491    0.158821663  -0.0270662628\nipsatized_TIPI9     0.268938383   -0.690397982   0.0655434271\nipsatized_TIPI10   -0.108530999   -0.002177791  -0.3767678405\n                 response_TIPI6 response_TIPI7 response_TIPI8\nid                  0.021000522    0.007644219     0.01618021\nipsatized_TIPI1    -0.666541441    0.170445729    -0.08266381\nipsatized_TIPI2    -0.038939637   -0.403279907     0.06565301\nipsatized_TIPI3     0.015568018   -0.020080341    -0.54989652\nipsatized_TIPI4     0.091005873   -0.050084957     0.15131155\nipsatized_TIPI5    -0.203227013    0.024189448    -0.02356731\nipsatized_TIPI6     0.953180313   -0.215281446    -0.08954131\nipsatized_TIPI7    -0.162399055    0.949232042    -0.08558253\nipsatized_TIPI8    -0.067303304   -0.119072017     0.95695523\nipsatized_TIPI9    -0.009290563   -0.028893032    -0.33029253\nipsatized_TIPI10    0.040201343   -0.228842712    -0.10619799\n                 response_TIPI9 response_TIPI10\nid                  -0.03949432    -0.017594425\nipsatized_TIPI1      0.09172718    -0.187414036\nipsatized_TIPI2     -0.26483551    -0.031356832\nipsatized_TIPI3      0.29771049    -0.076414836\nipsatized_TIPI4     -0.68790076     0.007123348\nipsatized_TIPI5      0.08228079    -0.365950413\nipsatized_TIPI6     -0.02645471     0.029629981\nipsatized_TIPI7      0.01615832    -0.176200329\nipsatized_TIPI8     -0.32648284    -0.089488624\nipsatized_TIPI9      0.95761526    -0.057303325\nipsatized_TIPI10    -0.06741043     0.941250723\n\nThe utility of safely() is especially apparent with this function. In addition to running code that would normally stop with an error, it also tells you in which specific function the error is occurring: in just_num().\n\n\n# Test it out with `safely()`\nsafe_ipsatize <- safely(ipsatize)\n\ntest3 %>% \n  safe_ipsatize()\n\n\n$result\nNULL\n\n$error\n<simpleError in just_num(.): No numeric columns.>\n\nSo now we have a list with the three dataframes. Our function-writing journey is officially complete. Finally, we can explore a couple of ways to use this function and its output.\nWhen using this function on projects for personality research, we may want to look at the correlations between raw and ipsatized data.\n\n\nipsdat <- ipsatize(data)\n\ntibble(\n  diag(ipsdat$correlation_matrix), colnames(ipsdat$ipsatized), colnames(ipsdat$raw)\n) %>% \n  rename(Correlation = `diag(ipsdat$correlation_matrix)`,\n         Ipsatized = `colnames(ipsdat$ipsatized)`,\n         Raw = `colnames(ipsdat$raw)`\n) %>% \n  filter(Ipsatized != \"id\",\n         Raw != \"id\") %>% \n  knitr::kable()\n\n\nCorrelation\nIpsatized\nRaw\n0.9599752\nipsatized_TIPI1\nresponse_TIPI1\n0.9542807\nipsatized_TIPI2\nresponse_TIPI2\n0.9488729\nipsatized_TIPI3\nresponse_TIPI3\n0.9621397\nipsatized_TIPI4\nresponse_TIPI4\n0.9192190\nipsatized_TIPI5\nresponse_TIPI5\n0.9531803\nipsatized_TIPI6\nresponse_TIPI6\n0.9492320\nipsatized_TIPI7\nresponse_TIPI7\n0.9569552\nipsatized_TIPI8\nresponse_TIPI8\n0.9576153\nipsatized_TIPI9\nresponse_TIPI9\n0.9412507\nipsatized_TIPI10\nresponse_TIPI10\n\nWe can also plot raw and ipsatized data. For example, let’s look at Item 1.\n\n\nTIPI_item1 <- data.frame(ipsdat$raw$response_TIPI1, ipsdat$ipsatized$ipsatized_TIPI1) %>% \n  rename(Raw = ipsdat.raw.response_TIPI1,\n         Ipsatized = ipsdat.ipsatized.ipsatized_TIPI1) %>% \n  pivot_longer(cols = Raw:Ipsatized, names_to = \"Data\", values_to = \"Item1\")\n\nTIPI_item1 %>% \n  ggplot() +\n  geom_density(aes(x = Item1, color = Data, fill = Data), alpha = .6) +\n  labs(x = \"TIPI Item 1\", y = \"Density\", title=\"Comparison of Raw and Ipsatized Scores\") +\n  colorblindr::scale_color_OkabeIto() +\n  colorblindr::scale_fill_OkabeIto() +\n  theme_minimal()\n\n\n\n\nThe correlation plot here indicates the multimodal nature of raw data which is reduced to a great extend in the ipsatized data. This helps to limit within person variability affecting the structural assessment of personality.\nThis concludes our tutorial on writing complex functions using a functional programming approach.\n\n\n\n",
    "preview": "posts/2021-05-28-write-a-function/write-a-function_files/figure-html5/unnamed-chunk-30-1.png",
    "last_modified": "2021-06-09T15:44:15-07:00",
    "input_file": {}
  }
]
