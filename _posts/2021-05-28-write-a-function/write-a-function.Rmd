---
title: "2. Write a Function!"
description: |
  Demonstration of how to write a function with personality research data.
author:
  - name: Raleigh Goodwin, Vinita Vader
date: 05-28-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

## Introduction

# Ipsatization

This is a tutorial on using functional programming to solve specific problems in research. This tutorial addresses the issue of __ipsatization__, which consists of methods of data transformation used in Personality Psychology and Social Psychology research. Ipsatization transforms each participant's ratings relative to their average response such that the total and the average of the participant's scores across all items in the data set are zero (or another constant for all people) ([Greer and Dunlap, 1997](https://psycnet.apa.org/record/1997-06270-006)). In simpler terms, it's a transformation in which you compute an average response for each participant and then subtract that average from each of their individual responses.

Packages such as [`multicon`](https://cran.r-project.org/web/packages/multicon/multicon.pdf) have built functions like [`ipsatize()`](https://rdrr.io/cran/multicon/man/ipsatize.html) which enable standardizing rows of the dataframes being studied. However it does not address the various types of ipsative scorings available for carrying out different transformations.

An important aspect of using data transformations involves understanding the relationship between raw data and transformed data. The purpose of the function built here will be to address this specific issue.

# Loading Libraries

Before we get started, we need to load the libraries necessary to complete this tutorial. Loading the entire library may not be always necessary, especially if you intend to use it only once. This will be the case for `rio`, `here`, and `knitr` in this tutorial, so you may choose not to load them here if you'd like.

```{r}
library(tidyverse)
library(purrr)
library(rio) # optional
library(here) # optional
library(knitr) # optional
```

# About the Data

For this tutorial, we will be working with a dataset containing the Ten Item Personality Inventory (TIPI; [Gosling, S. D., Rentfrow, P. J., & Swann, W. B., Jr., 2003](https://psycnet.apa.org/record/2003-09807-003)), a brief measure of the Big Five Personality Domains ([Goldberg, 1993](https://psycnet.apa.org/record/1993-17546-001)). Each item asks respondents to rate themselves on attributes (e.g., extroverted, critical, anxious, calm, etc.) using a Likert scale ranging from 1 to 7, wherein:\
\
1 = "Disagree strongly"\
2 = "Disagree moderately"\
3 = "Disagree a little"\
4 = "Neither agree nor disagree"\
5 = "Agree a little"\
6 = "Agree moderately"\
7 = "Agree strongly"

This particular dataset contains observations from N=2495 individuals who completed, among many other measures, the 10 TIPI items in 2016. Other variables included the Generic Conspiracist Beliefs Scale ([Brotherton et al., 2013](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00279/full)), various response time metrics, a vocabulary validity check, and demographics.

### Importing the Data

When importing data, two important things to keep in mind are your working directory and reproducibility. Where you save your files can impact the ease at which you can call them; you'll have the best luck saving data files of interest within the corresponding R Project. `rio`'s `import()` function provides an easy method for importing data files, including the ability to set the class of the data to tibble, which helps to retain the data in a format which is more amenable to data manipulation in `tidyverse`. To enhance reproducibility across different devices and potentially changing file paths, we'll use the `here()` function within the [`here`](https://here.r-lib.org/) package when specifying our file path.

```{r}
# Import data
full_df <- rio::import(here::here("content/dataCT.csv"), setclass = "tibble")
```

For the current project, we'll only be working with the TIPI items, so to simplify the dataframe we're using, we can select only those columns.

```{r}
# Select desired variables
data <- full_df %>% 
  select(TIPI1:TIPI10)
```

Now we can take a look at the data we'll be working with. The `kable()` function from the `knitr` package helps to format the data into a neat table.

```{r}
# Take a look at the data
data %>% 
  head(n = 5) %>% # Take a look at the first 5 rows of the resulting dataframe
  knitr::kable() # Format the output table neatly
```

With the libraries loaded and data imported, we can now begin building our function.

### Taking a look at the data

First, though, we can brush off our function-building skills with a simple function to start. In the code above, we used `head()` to take a look at the data and `kable()` to format it. We'll be doing this same process many, many times throughout the tutorial, so it would be a very useful function for us. This function, `glance()`, will have two arguments: df and nrows, which are the dataframe and the desired number of preview rows, respectively.

```{r}
glance <- function(df, nrows) {
  df %>% 
    head(n = nrows) %>% 
    knitr::kable()
}

# Test it out
data %>% 
  glance(5)
```

This works! Now we can move on to building something more complex.

## Building Functions

There are several ways in which one could go about building functions. The approach outlined here should be viewed as one of the several approaches to go about building functions.

As you think about building a function, keep in mind the purpose of why you set to build a function in the first place. Your function will ideally solve a problem specific to your analysis or can also be used by others to carry out their analyses.

Let's state the problem first: The difference between raw and ipsatized data has been studied to some extent leading to several debates amongst researchers questioning the utility of these methods. It is therefore important to look at correlations between the raw and ipsatized data. With this function, we will perform the ipsatization transformation and correlate its results with the raw data.

Now that we understand the problem, let's think about how our function could address this problem. Here are a sequence of questions which will help you think about the function you intend to build.

__What is the goal of this function?__\
Basically, what do we need this function to do? For the current tutorial, we are writing a function that ipsatizes any dataset, meaning that it will compute the means of the rows and subtract the mean from every score in the respective rows. Ideally, it will produce output in the form of a list containing the raw and transformed (i.e., ipsatized) data, along with a correlation matrix.

__How can we achieve this goal for a specific dataset?__\
As we learned in previous posts, when taking a functional programming approach to this problem, we should first attempt to solve it within a specific case. Once we've done so, we can then consider generalizing to a function. For this tutorial, we will be solving the problem first with the TIPI dataset, and then we can apply that solution to build the final function.

__How can we break the function's goal into smaller tasks?__\
Most likely, we aren't just going to be writing one function in this tutorial. Ideally, a function should complete exactly one task; therefore, when we are attempting to build a function to complete a complicated task like ipsatization, we will need to write multiple simple functions and combine them. Thus, it can be helpful to first outline and think through each step of the process and eventually create a function for each step.

### Solving for a specific case

To ipsatize the data, we need to calculate each participant's mean response to the TIPI scale items and then subtract each response by that mean. This means we need to be able to conduct these operations by row rather than by column. One of the easier ways to do this is to use `pivot_longer()` to transform the data into a "longer" format. 

First, though, we need to create an ID for each participant that can then be used to identify their responses once the data is transformed.

```{r}
data_id <- data %>% 
  mutate(id = c(1:nrow(data))) # Create ID variable

data_id %>%
  glance(5)
```

Now that we have an ID variable that can be used to identify each participant's responses, we can figure out how to create a column that calculates the mean of each rows using `pivot_longer()`.

```{r}
data_long <- data_id %>% 
  pivot_longer(cols = !id, names_to = "item", values_to = "response")

data_long %>% 
  glance(15)
```

Instead of participants' responses being organized by row, all responses are now contained in one column and can be identified using the corresponding ID and Item values. We can use `tidyverse`'s `group_by()` function to group this dataframe by participant ID and then compute 1) the mean for each group and 2) the difference between each response and the mean of its group.

```{r}
data_dev <- data_long %>% 
  group_by(id) %>% # Group by participant ID
  mutate(mean_row = mean(response, na.rm = TRUE), # Calculate participant mean
         ipsatized = response - mean_row) # Calculate individual response deviation from mean

data_dev %>% 
  glance(15)
```

Now, we can use `pivot_wider()` to transform the data back to its original format. Because we want the function output to be formatted as a list that contains the ipsatized data, raw data, and a correlation matrix of the two, it will be helpful to create two dataframes: an ipsatized dataframe and a raw dataframe.

```{r}
# Create ipsatized data frame
data_ips <- data_dev %>%
  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%
  select(id, contains("ipsatized")) %>%
   ungroup()

# Create raw dataframe
data_raw <- data_dev %>%
  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%
  select(id, contains("response")) %>%
   ungroup()

# Take a look at the results
data_ips %>% 
  glance(15)

data_raw %>% 
  glance(15)
```

Lastly, let's create that list.

```{r}
list_output <- list("ipsatized" = data_ips,
          "raw" = data_raw,
          "correlation_matrix" = cor(data_ips, data_raw))

list_output
```

This list is what we set out to create! We've achieved our goal using this dataset.\
Now that we've solved this problem in a specific case, we can begin to generalize it to a function. Or, rather, a set of functions!

### Applying specific case to generalized function(s)

Since we want each function to only do one task, we can first outline the individual tasks that make up the ipsatization process.

1. Add an ID variable to the dataframe
2. Pivot the data to a longer format
3. Calculate the mean of each row and transform each response by subtracting the row mean from it
4. Pivot the data back to a wider format
5. Create a list to organize the output

Now we can set out to make a function to complete each task. These functions don't ever have to be used on their own; in the end, they'll all be combined into a final, single function. This may seem like it's making work more complicated, but this approach enhances readability of your code and aids in troubleshooting errors.\
Since we've done the majority of the problem solving already, we can essentially copy and paste our code from above, making sure to adapt as necessary to the function format. Luckily, for the current tutorial, these changes mostly consist of changing the name of the dataframe input to "df," which is the name of our only argument in this function.\
After we build each function, we can test that it works by running it with a couple of datasets. Since we wrote this code with the TIPI dataset in mind, we can also test it with another dataset in order to catch any potential issues that may crop up when using different data. Though ipsatization is typically used in personality research, we'll use the `iris` dataset as our second test case for simplicity.

1. Add an ID variable to the dataframe

```{r}
add_id <- function(df) {
  df %>%
    mutate(id = c(1:nrow(df)))
}
```

```{r}
# Test it out
test1 <- data %>% 
  add_id()

test2 <- iris %>% 
  add_id()

test1 %>%  
  glance(5)

test2 %>%  
  glance(5)
```

It works! However, when looking at the output for the dataframe `iris`, you may notice a difference between it and the specific case in which we originally wrote this code: This dataset contains character data in addition to numeric data. Before we go any further, we have to write code that extracts only numeric columns from the dataframe of interest.

1.5. Select only numeric columns from dataframe

We can accomplish this using the `map_lgl()` function from the `purrr` package, which maps the `is.numeric()` function to every column in the dataframe and is appropriate in this case because the output will be a logical vector. This will ensure that all the columns in the dataframe we are working with are numeric. First, we can try writing this code to solve the problem in the `iris` dataset specifically.

```{r}
iris[ , purrr::map_lgl(iris, is.numeric)] %>% 
  glance(10)
```

Just like before, we can now translate that code into a function. This time, we'll also add a condition to our function: If there are no numeric columns in the dataset (i.e., if the sum of all possible numeric columns is 0), the loop will stop and the function will throw an error message. If there is at least one numeric column, the function will run as normal.

```{r}
just_num <- function(df) {
  if(sum(purrr::map_lgl(df, is.numeric)) == 0) {
    stop("No numeric columns.")
  }
    else{
      df1 <- df[ , purrr::map_lgl(df, is.numeric)]
      df1
    }
}
```

```{r}
# Test it out
test1 <- test1 %>% 
  just_num()

test2 <- test2 %>% 
  just_num()

test1 %>% 
  glance(15)

test2 %>% 
  glance(15)
```

To test our condition, we should also test this function with a dataset that has no numeric columns. 

```{r}
test3 <- tibble(letters, LETTERS)

test3 %>% 
  glance(5)
```

When doing so, we can also explore the utility of the `safely()` function from `purrr`. If we use `just_num()` on `test3` and it throws the correct error, we will not be able to knit this document. `safely()` allows you to create "safe" functions that will return output that also "captures" errors, which would normally stop a function from being able to run. This can be very useful for troubleshooting and will help us test our function on `test3`.

```{r}
# Test it out with `safely()`
safe_just_num <- purrr::safely(just_num)

test3 %>% 
  safe_just_num()

# vs:

test4 <- tibble(1:5, 6:10)

test4 %>% 
  safe_just_num()
```

Critically, this function will allow our final function to generalize to multiple different datasets. With that done, we can continue with the rest of our outlined tasks.

2. Pivot the data to a longer format

```{r}
lengthen_data <- function(df) {
  df %>% 
  pivot_longer(cols = !id, names_to = "item", values_to = "response")
}
```

```{r}
# Test it out
test1 <- test1 %>% 
  lengthen_data()

test2 <- test2 %>% 
  lengthen_data()

test1 %>% 
  glance(15)

test2 %>% 
  glance(15)
```

3. Calculate the mean of each row and transform each response by subtracting the row mean from it

```{r}
transform_data <- function(df) {
  df %>% 
  group_by(id) %>% # Group by participant ID
  mutate(mean_row = mean(response, na.rm = TRUE), # Calculate participant mean
         ipsatized = response - mean_row) # Calculate individual response deviation from mean
}
```

```{r}
# Test it out
test1 <- test1 %>% 
  transform_data()

test2 <- test2 %>% 
  transform_data()

test1 %>% 
  glance(15)

test2 %>% 
  glance(15)
```

4. Pivot the data back to a wider format

```{r}
widen_data <- function(df) {
  # Create ipsatized data frame
data_ips_id <- df %>%
  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%
  select(id, contains("ipsatized")) %>%
   ungroup()

# Create raw dataframe
data_raw_id <- df %>%
  pivot_wider(id_cols = id, names_from = item, values_from = c(response, ipsatized)) %>%
  select(id, contains("response")) %>%
   ungroup()

# Functions don't return multiple objects, so we have to wrap them into a single list
outputlist <- list("data_ips" = data_ips, 
                   "data_raw" = data_raw)

# Return list
return(outputlist)
}
```

```{r}
# Test it out
test1 <- test1 %>% 
  widen_data()

test2 <- test2 %>% 
  widen_data()

test1

test2
```

5. Create a list to organize the desired, final output

```{r}
ipsatize_list <- function(df) {
  list("ipsatized" = df$data_ips,
          "raw" = df$data_raw,
          "correlation_matrix" = cor(df$data_ips, df$data_raw))
}
```

```{r}
# Test it out
test1 %>%
  ipsatize_list()

test2 %>%
  ipsatize_list()
```

Now let's combine all of these functions together!

```{r}
ipsatize <- function(df) {
  df %>% 
    just_num() %>% 
    add_id() %>% 
    lengthen_data() %>% 
    transform_data() %>% 
    widen_data() %>% 
    ipsatize_list()
}
```

```{r}
# Test it out
ipsatize(data)
ipsatize(iris)
```

The utility of `safely()` is especially apparent with this function. In addition to running code that would normally stop with an error, it also tells you in which specific function the error is occurring: in `just_num()`.

```{r}
# Test it out with `safely()`
safe_ipsatize <- safely(ipsatize)

test3 %>% 
  safe_ipsatize()
```

So now we have a list with the three dataframes. Our function-writing journey is officially complete. Finally, we can explore a couple of ways to use this function and its output.\
\
When using this function on projects for personality research, we may want to look at the correlations between raw and ipsatized data.

```{r echo=TRUE}
ipsdat <- ipsatize(data)

tibble(
  diag(ipsdat$correlation_matrix), colnames(ipsdat$ipsatized), colnames(ipsdat$raw)
) %>% 
  rename(Correlation = `diag(ipsdat$correlation_matrix)`,
         Ipsatized = `colnames(ipsdat$ipsatized)`,
         Raw = `colnames(ipsdat$raw)`
) %>% 
  filter(Ipsatized != "id",
         Raw != "id") %>% 
  knitr::kable()
```

We can also plot raw and ipsatized data. For example, let's look at Item 1.

```{r}
TIPI_item1 <- data.frame(ipsdat$raw$response_TIPI1, ipsdat$ipsatized$ipsatized_TIPI1) %>% 
  rename(Raw = ipsdat.raw.response_TIPI1,
         Ipsatized = ipsdat.ipsatized.ipsatized_TIPI1) %>% 
  pivot_longer(cols = Raw:Ipsatized, names_to = "Data", values_to = "Item1")

TIPI_item1 %>% 
  ggplot() +
  geom_density(aes(x = Item1, color = Data, fill = Data), alpha = .6) +
  labs(x = "TIPI Item 1", y = "Density", title="Comparison of \n raw and ipsatized scores") +
  colorblindr::scale_color_OkabeIto() +
  colorblindr::scale_fill_OkabeIto() +
  theme_minimal()
```

The correlation plot here indicates the multimodal nature of raw data which is reduced to a great extend in the ipsatized data. This helps to limit within person variability affecting the structural assessment of personality. 